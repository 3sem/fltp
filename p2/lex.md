### 1. Задача лексического анализа (Lexical Analysis)?

Ззадача — преобразовать последовательность входных символов (исходный код, текст разметки, данные и т.д.) в последовательность осмысленных блоков, называемых **токенами (tokens)**.

Представьте, что вы читаете предложение на естественном языке: вы не воспринимаете его как просто поток букв, а разбиваете на слова. Лексический анализатор делает то же самое с формальным языком.

**Основные понятия:**

*   **Исходный текст:** Исходная последовательность символов (например, `price = 42 + tax;`).
*   **Токен (Token):** Это структура, содержащая:
    *   **Тип (Type):** Категория, к которой принадлежит лексема (например, "число", "идентификатор", "ключевое слово", "оператор").
    *   **Значение (Value):** Фактическая строка символов, из которой состояла лексема (например, `"42"`, `"price"`).
    *   **Местоположение:** Номер строки и столбца в исходном файле (для сообщений об ошибках).
*   **Лексема (Lexeme):** Конкретная последовательность символов, соответствующая шаблону токена. Это "сырое" значение.
*   **Паттерн (Pattern):** Правило (часто описываемое регулярным выражением), которое определяет, как выглядит лексема для данного типа токена.

**Пример:**
Для строки `price = 42 + tax;`

| Лексема (`lexeme`) | Тип токена (`token type`)     | Возможное значение (`value`)      |
| ------------------ | ----------------------------- | --------------------------------- |
| `price`            | ИДЕНТИФИКАТОР (IDENTIFIER)    | Указатель на запись в таблице символов |
| `=`                | ОПЕРАТОР_ПРИСВАИВАНИЯ (ASSIGN)| (не требуется)                    |
| `42`               | ЧИСЛО (NUMBER)                | Целое число 42                    |
| `+`                | ОПЕРАТОР_ПЛЮС (PLUS)          | (не требуется)                    |
| `tax`              | ИДЕНТИФИКАТОР (IDENTIFIER)    | Указатель на запись в таблице символов |
| `;`                | ТОЧКА_С_ЗАПЯТОЙ (SEMICOLON)   | (не требуется)                    |

**Задачи лексического анализатора:**
1.  **Разбиение на лексемы:** Убрать пробелы, табуляции, комментарии (все, что считается "пробельными" символами) и выделить значимые последовательности.
2.  **Классификация:** Определить тип каждой лексемы.
3.  **Сообщение об ошибках:** Обнаружить и сообщить о недопустимых символах (например, `@` в языке C).
4.  **Интеграция с парсером:** "Подавать" токены следующему этапу — синтаксическому анализатору (парсеру).

---

### 2. Что такое GNU Flex?

**GNU Flex (Fast Lexical Analyzer Generator)** — **генератор анализаторов**. Это утилита, которая по формальному описанию токенов (написанному на ее собственном языке) генерирует исходный код лексического анализатора.

**Основная идея:** Вы описываете, *что* нужно искать с помощью регулярных выражений, а Flex генерирует код автомата, который распознает эти паттерны в тексте.

---

### 3. Как работает Flex? Структура flex-спецификации

Файл с исходным кодом для Flex (обычно с расширением `.l`) состоит из трех разделов, разделенных символами `%%`:

```
%{
    ... С-код (заголовки, объявления) ...
%}
    ... Определения (definitions) ...
%%
    ... Правила (rules) ...
%%
    ... Пользовательский С-код (дополнительные функции) ...
```

Разберем каждый раздел на примере простого калькулятора.

#### Пример: Лексер для простых арифметических выражений

```c
%{
/* Раздел 1: С-код, который будет вставлен в начало сгенерированного файла */
#include <stdio.h>
// Мы будем возвращать числа как целые, а идентификаторы как строки.
// Для парсера обычно здесь подключают "y.tab.h", если используется Bison.
%}

/* Раздел 2: Определения (Макросы для упрощения регулярных выражений) */
DIGIT    [0-9]
ID       [a-zA-Z_][a-zA-Z0-9_]*

/* Подавление предупреждения компилятора о неиспользуемой функции в простых примерах */
%option noyywrap

%%
    /* Раздел 3: Правила (Паттерн -> Действие на С) */

    /* Ключевые слова (некоторые) */
"if"     { printf("KEYWORD_IF\n"); }
"else"   { printf("KEYWORD_ELSE\n"); }

    /* Операторы и скобки */
"+"      { printf("OPERATOR_PLUS\n"); }
"-"      { printf("OPERATOR_MINUS\n"); }
"*"      { printf("OPERATOR_MULTIPLY\n"); }
"/"      { printf("OPERATOR_DIVIDE\n"); }
"="      { printf("OPERATOR_ASSIGN\n"); }
"("      { printf("LEFT_PAREN\n"); }
")"      { printf("RIGHT_PAREN\n"); }

    /* Числа: преобразуем лексему в целое число */
{DIGIT}+ {
        printf("NUMBER: %d\n", atoi(yytext));
    }

    /* Идентификаторы */
{ID}     {
        printf("IDENTIFIER: %s\n", yytext);
    }

    /* Игнорируем пробельные символы */
[ \t\n]  ; /* Ничего не делаем */

    /* Обработка ошибок: любой другой символ */
.        {
        printf("Error: Unexpected character '%s'\n", yytext);
    }

%%

/* Раздел 4: Пользовательский код */
int main(int argc, char **argv) {
    // yyin - глобальная переменная Flex для входного файла. По умолчанию stdin.
    if (argc > 1) {
        yyin = fopen(argv[1], "r");
    }
    // yylex() - главная функция, сгенерированная Flex, которая запускает анализ.
    yylex();
    return 0;
}
```

#### Ключевые переменные и функции Flex:

*   `yylex()`: Сгенерированная функция, при каждом вызове которой возвращается следующий токен.
*   `yytext`: Указатель на строку (лексему), которая соответствует найденному паттерну.
*   `yyleng`: Длина текущей лексемы.
*   `yyin`: Указатель на входной файл (по умолчанию `stdin`).
*   `yywrap()`: Функция, вызываемая когда лексер достигает конца файла. Если она возвращает 1, анализ завершается. Часто используют `%option noyywrap`, чтобы отключить эту функциональность.

---

### 4. Процесс работы с Flex

1.  **Написание спецификации:** Вы создаете файл, например, `lexer.l`.
2.  **Генерация C-кода:** Вы запускаете команду `flex lexer.l`. Это создаст файл `lex.yy.c`.
3.  **Компиляция:** Вы компилируете сгенерированный код вместе с вашим основным проектом: `gcc -o my_lexer lex.yy.c`.
4.  **Запуск:** Запускаете исполняемый файл: `./my_lexer` (оно будет читать из `stdin`) или `./my_lexer input_file.txt`.

---

### 5. Взаимодействие Flex и Bison (Yacc)

Отдельно лексер полезен для простых задач (например, логирования, подсчета статистики). Но как правило используется паре с **генератором парсеров**, типа **GNU Bison** (аналог Yacc).

**Схема работы:**
1.  **Bison** генерирует парсер на основе грамматики языка. Он определяет, какие токены ему нужны (например, `NUMBER`, `IDENTIFIER`, `PLUS`).
2.  Эти токены объявляются в заголовочном файле (часто `y.tab.h`), который включается в секцию определений Flex.
3.  **Flex** настраивается так, чтобы его правила вместо `printf` возвращали эти токены с помощью макроса `return`.
    ```c
    // В правилах Flex
    {DIGIT}+  { return NUMBER; }
    "+"       { return PLUS; }
    ```
4.  Парсер (функция `yyparse()`, сгенерированная Bison) повторно вызывает функцию `yylex()`, чтобы получить следующий токен и на их основе строить дерево разбора согласно грамматике.
*   **GNU Flex** — мощный инструмент для автоматического создания быстрых и эффективных лексических анализаторов на C.
*   Вы описываете токены с помощью **регулярных выражений** и **действий на C**, а Flex генерирует код, который делает всю "грязную" работу по поиску и сопоставлению.
*   Flex идеально сочетается с Bison для создания полноценных компиляторов и интерпретаторов.
